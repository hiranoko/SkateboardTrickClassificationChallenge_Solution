{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.constants import SUBJECT_IDS\n",
    "from src.config import CFG\n",
    "from src.dataset.csv import read_csv\n",
    "from src.dataset.dataset import CustomDataset\n",
    "from src.dataset.eeg import butter_bandpass_filter\n",
    "from src.model.encoder import Encoder1D\n",
    "from src.runner.base import run_fold, run_oof\n",
    "from src.utils.util import seed_everything\n",
    "\n",
    "# print(isort.code(_ih[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConfig(CFG):\n",
    "    def get_in_channels(self):\n",
    "        if self.target_subjectid == \"subject0\":\n",
    "            return 66\n",
    "        elif self.target_subjectid == \"subject1\":\n",
    "            return 60\n",
    "        elif self.target_subjectid == \"subject2\":\n",
    "            return 67\n",
    "        elif self.target_subjectid == \"subject3\":\n",
    "            return 68\n",
    "        elif self.target_subjectid == \"subject4\":\n",
    "            return 65\n",
    "        else:\n",
    "            raise ValueError(\"Invalid target_subjectid\")\n",
    "\n",
    "    def remove_non_use_ch(self, signal: np.ndarray):\n",
    "        if self.target_subjectid == \"subject0\":\n",
    "            # 72ch -> 66ch\n",
    "            signal = np.delete(signal, [13, 28, 64, 68, 70, 71], axis=0)\n",
    "        elif self.target_subjectid == \"subject1\":\n",
    "            # 72ch -> 60ch\n",
    "            signal = np.delete(\n",
    "                signal, [8, 12, 13, 14, 18, 39, 56, 58, 63, 66, 68, 70], axis=0\n",
    "            )\n",
    "        elif self.target_subjectid == \"subject2\":\n",
    "            # 72ch -> 67ch\n",
    "            signal = np.delete(signal, [39, 52, 66, 68, 70], axis=0)\n",
    "            # 52 ch is large std\n",
    "        elif self.target_subjectid == \"subject3\":\n",
    "            # 72ch -> 68ch\n",
    "            signal = np.delete(signal, [13, 39, 56, 70], axis=0)\n",
    "        elif self.target_subjectid == \"subject4\":\n",
    "            # 72ch -> 65ch\n",
    "            signal = np.delete(signal, [11, 13, 24, 39, 65, 66, 70], axis=0)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid target_subjectid\")\n",
    "        return signal\n",
    "\n",
    "    def train_preprocess(self, signal: np.ndarray):\n",
    "        signal = signal - signal.mean(axis=1, keepdims=True)\n",
    "        signal = self.remove_non_use_ch(signal)\n",
    "        signal = butter_bandpass_filter(signal, 2, 125, 500)\n",
    "        return signal\n",
    "\n",
    "    def test_preprocess(self, signal: np.ndarray):\n",
    "        signal = signal - signal.mean(axis=1, keepdims=True)\n",
    "        signal = self.remove_non_use_ch(signal)\n",
    "        signal = butter_bandpass_filter(signal, 2, 125, 500)\n",
    "        return signal\n",
    "\n",
    "    def model_parameters(self):\n",
    "        in_chanaels = self.get_in_channels()\n",
    "        return {\n",
    "            \"in_channels\": in_chanaels,\n",
    "            \"num_classes\": 3,\n",
    "            \"hidden_channels\": [728, 259, 253],\n",
    "            \"conv_types\": [\"standard\", \"standard\", \"standard\"],\n",
    "            \"kernel_size\": 3,\n",
    "            \"pooling_types\": [\"max\", \"max\", \"avg\"],\n",
    "            \"activation\": \"leaky_relu\",\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def training_parameters():\n",
    "        return {\"lr\": 1e-3, \"epochs\": 20}\n",
    "\n",
    "\n",
    "cfg = CustomConfig(exp_name=\"tmp\", target_subjectid=\"subject0\")\n",
    "print(Encoder1D(**cfg.model_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Run OOF](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"encoder1d\"\n",
    "target = \"classification1\"\n",
    "visualize = False\n",
    "oof_columns = [\"backside_kickturn\", \"frontside_kickturn\", \"pumping\", \"pred\"]\n",
    "train_df = read_csv(f\"../input/{target}/train.csv\", \"npy\")[\n",
    "    [\"npy\", \"subject_id\", \"label\", \"oe_label\", \"train\", \"oe_train\"]\n",
    "]\n",
    "train_df[oof_columns] = -1.0\n",
    "\n",
    "for subject_id in SUBJECT_IDS:\n",
    "    print(f\"Subject ID : {subject_id}\")\n",
    "    seed_everything(42)\n",
    "    cfg = CustomConfig(exp_name=exp_name, target_subjectid=subject_id, target=target)\n",
    "    working_dir = Path(f\"../output/{target}/{cfg.exp_name}/{cfg.target_subjectid}\")\n",
    "\n",
    "    # Train and validate for each fold\n",
    "    for fold in range(len(cfg.fold_dict)):\n",
    "        run_fold(\n",
    "            cfg=cfg,\n",
    "            model=Encoder1D(**cfg.model_parameters()),\n",
    "            df=cfg.train_df.copy(),\n",
    "            fold=fold,\n",
    "            working_dir=working_dir,\n",
    "            silent=True,\n",
    "            visualize=visualize,\n",
    "        )\n",
    "\n",
    "    # Run OOF\n",
    "    oof_df = run_oof(\n",
    "        cfg=cfg,\n",
    "        model=Encoder1D(**cfg.model_parameters()),\n",
    "        oof_df=cfg.oof_df.copy(),\n",
    "        working_dir=working_dir,\n",
    "        silent=True,\n",
    "    )\n",
    "    accuracy = accuracy_score(oof_df[\"pred\"], oof_df[cfg.target_col])\n",
    "    print(f\"OOF Accuracy : {accuracy}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Merge OOF predictions into train_df\n",
    "    train_df = train_df.merge(\n",
    "        oof_df[[\"npy\"] + oof_columns], on=\"npy\", how=\"left\", suffixes=(\"\", \"_oof\")\n",
    "    )\n",
    "    for col in oof_columns:\n",
    "        train_df.loc[train_df[f\"{col}_oof\"].notnull(), col] = train_df[f\"{col}_oof\"]\n",
    "    train_df = train_df.drop(columns=[f\"{col}_oof\" for col in oof_columns])\n",
    "\n",
    "# Final accuracy\n",
    "score = accuracy_score(y_true=train_df.oe_label, y_pred=train_df.pred)\n",
    "print(f\"Final Accuracy : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[Submit](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"encoder1d\"\n",
    "target = \"classification1\"\n",
    "\n",
    "test_df = read_csv(f\"../input/{target}/test.csv\", \"npy\")\n",
    "working_dir = Path(f\"../output/{target}/{exp_name}\")\n",
    "\n",
    "pred_results = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    npy_path = row[\"npy\"]\n",
    "    subject_id = row[\"subject_id\"]\n",
    "\n",
    "    # モデルの初期化\n",
    "    cfg = CustomConfig(exp_name=exp_name, target_subjectid=subject_id, target=target)\n",
    "    model = Encoder1D(**cfg.model_parameters()).to(cfg.device)\n",
    "    model.eval()\n",
    "\n",
    "    # モデルパスの取得\n",
    "    model_pathes = sorted(list((working_dir / f\"{subject_id}\").rglob(\"*.pth\")))\n",
    "\n",
    "    # 信号データの読み込みと前処理\n",
    "    signal = (\n",
    "        torch.tensor(cfg.test_preprocess(np.load(npy_path)).astype(np.float32))\n",
    "        .unsqueeze(0)\n",
    "        .to(cfg.device)\n",
    "    )\n",
    "\n",
    "    # 複数モデルの予測を蓄積\n",
    "    raw_preds = []\n",
    "    with torch.no_grad():\n",
    "        for model_path in model_pathes:\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            pred = model(signal).cpu()  # 予測を取得\n",
    "            raw_preds.append(pred)\n",
    "\n",
    "    # 平均値を計算して分類\n",
    "    raw_preds = torch.stack(raw_preds).mean(0).softmax(-1).numpy()[0]\n",
    "    pred_cls = np.argmax(raw_preds)\n",
    "    pred_str = list(cfg.target_dict.keys())[pred_cls]\n",
    "\n",
    "    # 結果を保存\n",
    "    pred_results.append(\n",
    "        [str(npy_path.stem), raw_preds[0], raw_preds[1], raw_preds[2], pred_str]\n",
    "    )\n",
    "\n",
    "# 結果を保存\n",
    "submit_df = pd.DataFrame(\n",
    "    pred_results,\n",
    "    columns=[\"npy\", \"backside_kickturn\", \"frontside_kickturn\", \"pumping\", \"pred\"],\n",
    ")\n",
    "submit_df[[\"npy\", \"pred\"]].to_csv(\n",
    "    working_dir / \"submission.csv\", index=False, header=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
